{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROJECT ABSTRACT \n",
    "\n",
    "With all the code computed on other notebookes:\n",
    "\n",
    " **1- Spotify API** - where I did my first connection to the API, providing it with like and disliked songs, as well as my musical journey data.\n",
    "\n",
    " **2- EDA** - where I explored all Spotify features based on the two groups in study.\n",
    "\n",
    " **3- My Musical Journey** - also a kind of EDA notebook. However, in this one I analysed my top year playlists to evaluate the evolution of my music taste from 2016 to 2019. \n",
    "\n",
    " **4- Supervised ML** - tested multiple suprevised learning classifiers getting to a 86% Accuracy with Random Forest. I have now a pretty good algorithm that aimns to detect if I like a song or not, as well as the prob of that event happening.\n",
    "\n",
    " **5- Test on other's playlists** - used the best algorithm evaluated on ML notebook and applied to outside data - songs from friend's playlists - meaning neither data from the traning nor the test set.\n",
    "\n",
    " **6- Unsupervised Learning** - without any song labeling, used the whole dataset (liked + disliked songs) to extract knowledge based on any patterns: Clustering, Dimensionality Reduction.\n",
    "\n",
    "Finally, in this script I aim to produce a final product where the user can input his/hers/theirs **(public) playlsit URI** and get an  **Exploratory Data Analysis on the songs' features, as well as new song recomendations.** This will be produced based on Unsupervised Learning techniques, since we can assume the shared playlist will be a collection of liked songs and therefore we can't apply labelling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import spotipy.util as util\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "import plotly.express as px\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_1samp, ttest_rel, ttest_ind\n",
    "from IPython.display import display, Image, SVG, Math, YouTubeVideo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'britopereiraa'\n",
    "client_id ='17a3ed14ab434b33b28f19f8bea3337d'\n",
    "client_secret = '7f848f9d2a024b15be5fa776b4dc7a05'\n",
    "redirect_uri = 'http://localhost:7777/callback'\n",
    "scope = 'user-read-recently-played'\n",
    "\n",
    "token = util.prompt_for_user_token(username=username, \n",
    "                                   scope=scope, \n",
    "                                   client_id=client_id,   \n",
    "                                   client_secret=client_secret,     \n",
    "                                   redirect_uri=redirect_uri)\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id, client_secret) \n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_function(username, uri):\n",
    "    uri = playlist_uri    \n",
    "    username = username\n",
    "    playlist_id = uri\n",
    "    results = {'items':[]}\n",
    "\n",
    "    for n in range(0,3000,100):\n",
    "        new = sp.user_playlist_tracks(username, playlist_id,  offset = n)\n",
    "        results['items'] += new['items']\n",
    "\n",
    "        playlist_tracks_data = results\n",
    "        playlist_tracks_id = []\n",
    "        playlist_tracks_titles = []\n",
    "        playlist_tracks_artists = []\n",
    "\n",
    "        for track in playlist_tracks_data['items']:\n",
    "            playlist_tracks_id.append(track['track']['id'])\n",
    "            playlist_tracks_titles.append(track['track']['name'])\n",
    "\n",
    "        #adds a list of all artists involved in the song to the list of artists for the playlist\n",
    "            for artist in track['track']['artists']:\n",
    "                artist_list = []\n",
    "                artist_list.append(artist['name'])\n",
    "            playlist_tracks_artists.append(artist_list[0])\n",
    "    \n",
    "    #some tracks might have none id\n",
    "    playlist_tracks_id = list(filter(None, playlist_tracks_id)) \n",
    "    \n",
    "    df = pd.DataFrame([])\n",
    "    for i in range(0, len(playlist_tracks_id)):\n",
    "        features = sp.audio_features(playlist_tracks_id[i])\n",
    "        features_df = pd.DataFrame(features)\n",
    "        df = df.append(features_df)\n",
    "       \n",
    "\n",
    "    df['title'] = playlist_tracks_titles\n",
    "    #features_df['first_artist'] = playlist_tracks_first_artists\n",
    "    df['main_artist'] = playlist_tracks_artists\n",
    "    #features_df = features_df.set_index('id')\n",
    "    df = df[['id', 'title', 'main_artist',\n",
    "                               'danceability', 'energy', 'key', 'loudness',\n",
    "                               'mode', 'acousticness', 'instrumentalness',\n",
    "                               'liveness', 'valence', 'tempo',\n",
    "                               'duration_ms', 'time_signature']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USER PLAYLIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input variables\n",
    "playlist_uri =\"2ERd3YQjKnGSEyInrwYPRh\"\n",
    "username = \"Jo√£o Fanha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = master_function(username,playlist_uri)\n",
    "user_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the all songs playlist: \n",
    "\n",
    "A playlist with over 5000 songs of all Genre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-72eb54c9ce68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#check recomended songs that are not in the playlist already:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mall_songs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_songs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_songs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mall_songs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "features = ['danceability', 'energy', 'key','loudness', 'mode', 'acousticness', 'instrumentalness', 'liveness','valence', 'tempo']\n",
    "\n",
    "#import dataset created in other jupyter notebook\n",
    "all_songs = pd.read_csv('../data/all_songs.csv')\n",
    "\n",
    "#drop duplicates\n",
    "all_songs.drop_duplicates(subset =\"id\", \n",
    "                     keep = False, inplace = True)\n",
    "\n",
    "\n",
    "#check recomended songs that are not in the playlist already:\n",
    "\n",
    "all_songs = all_songs.loc[~((all_songs.id.isin(df['id']))),:]\n",
    "all_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Songs Recomendations\n",
    "\n",
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features scaling \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(all_songs[features])\n",
    "\n",
    "all_songs_features_scaled = scaler.transform(all_songs[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN CLUSTERING IN ALL SONGS\n",
    "\n",
    "X = all_songs_features_scaled\n",
    "# Instantiate the clustering model and visualizer\n",
    "model = KMeans()\n",
    "visualizer = KElbowVisualizer(model, k=(1,12))\n",
    "\n",
    "visualizer.fit(X)        # Fit the data to the visualizer\n",
    "visualizer.show()        # Finalize and render the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the data into clusters\n",
    "\n",
    "kmean = KMeans(n_clusters=4)\n",
    "kmean.fit(all_songs_features_scaled)\n",
    "\n",
    "pred = kmean.labels_\n",
    "all_songs['labels'] = pred\n",
    "\n",
    "#check clusters\n",
    "all_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_songs['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APPLY CLUSTERS\n",
    "\n",
    "df = user_df.copy()\n",
    "pred_df = kmean.predict(df[features])\n",
    "df['songs group'] = pred_df\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.drop(columns=['index'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA on all songs\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=3, random_state=42)\n",
    "df_pca_all_songs = pd.DataFrame(data=pca.fit_transform(all_songs_features_scaled), columns=['PC1','PC2','PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_\n",
    "print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(pca.components_, cmap='viridis')\n",
    "plt.yticks([0, 1, 2], [\"First component\", \"Second component\", \"Third component\"])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(all_songs[features].columns)),all_songs[features], rotation=60, ha='left')\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Principal components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_all_songs = df_pca_all_songs.merge(all_songs, left_index=True, right_index=True)\n",
    "df_pca_all_songs = df_pca_all_songs[['PC1', 'PC2', 'PC3', 'title', 'main_artist']]\n",
    "\n",
    "df_pca_all_songs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA with friend's playlist\n",
    "\n",
    "#features scaling \n",
    "df_scaled = scaler.transform(df[features])\n",
    "\n",
    "#use trained PCA\n",
    "df_pca = pd.DataFrame(data=pca.transform(df_scaled), columns=['PC1','PC2','PC3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = df_pca.merge(df, left_index=True, right_index=True)\n",
    "df_pca = df_pca[['PC1', 'PC2', 'PC3', 'title', 'main_artist']]\n",
    "\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get recomendations with PCA and Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import KDTree\n",
    "columns = ['PC1', 'PC2', 'PC3']\n",
    "\n",
    "kdB = KDTree(df_pca_all_songs[columns].values)#all songs\n",
    "neighbours = kdB.query(df_pca[columns].values, k=1)[-1]\n",
    "\n",
    "print(neighbours)\n",
    "\n",
    "#k desired number of neighbors: this case I chose 1 neighbour song\n",
    "#returns indices of 1-neighbors for all rows/points in our songs \"database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendations = all_songs[all_songs.index.isin(neighbours)]\n",
    "recomendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## recomendations output \n",
    "\n",
    "recomendations_output = recomendations[['title', 'main_artist']]\n",
    "recomendations_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obamas = pd.read_csv('../data/obamas.csv')\n",
    "pitchfork = pd.read_csv('../data/pitchfork.csv')\n",
    "billboard = pd.read_csv('../data/billboard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obamas['Playlist'] = 'The Obamas'\n",
    "pitchfork['Playlist'] = 'Pitchfork'\n",
    "billboard['Playlist'] = 'Billboard Top 100'\n",
    "user_df['Playlist'] = 'Your Songs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [billboard, pitchfork, obamas, user_df]\n",
    "\n",
    "data = pd.concat(frames)\n",
    "data = data.reset_index()\n",
    "data = data.drop(columns=['index'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Min-max scaling\n",
    "\n",
    "data_scaled = pd.DataFrame(MinMaxScaler().fit_transform(data[features]), \n",
    "                         columns=data[features].columns)\n",
    "data_scaled['Playlist'] = data['Playlist']\n",
    "\n",
    "df_radar = data_scaled.groupby('Playlist').mean().reset_index() \\\n",
    "                    .melt(id_vars='Playlist', var_name=\"features\", value_name=\"avg\") \\\n",
    "                    .sort_values(by=['Playlist','features']).reset_index(drop=True)\n",
    "\n",
    "px.line_polar(df_radar, \n",
    "              r=\"avg\", \n",
    "              theta=\"features\", \n",
    "              title='Mean Values of Each Track Features',\n",
    "              color=\"Playlist\", \n",
    "              line_close=True,\n",
    "              line_shape='spline',\n",
    "              range_r=[0, 0.9],\n",
    "              color_discrete_sequence=px.colors.cyclical.mygbm[:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists = list(data['Playlist'].unique())\n",
    "playlists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hipster or Mainstream?\n",
    "\n",
    "Let's compare your songs to Pitchfork best albums and best new music, as well as to Billboard week's Top 100 hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../images/new_highfid.png',width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    plt.figure(figsize=(7,4))\n",
    "\n",
    "    sns.kdeplot(data[data['Playlist']== 'Your Songs'][feature], label='Your Songs')\n",
    "    sns.kdeplot(data[data['Playlist']== 'Pitchfork'][feature],   label='Pitchfork')\n",
    "    sns.kdeplot(data[data['Playlist']== 'Billboard Top 100'][feature],   label='Billboard Top 100')  \n",
    "    plt.grid(b=None)\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../images/old_highfid.png',width = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You a Obama?\n",
    "\n",
    "Let's see if you got the musical taste of a Obama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in features:\n",
    "    plt.figure(figsize=(7,4))\n",
    "\n",
    "    sns.kdeplot(data[data['Playlist']== 'Your Songs'][feature], label='Your Songs')\n",
    "    sns.kdeplot(data[data['Playlist']== 'The Obamas'][feature],  label='The Obamas')\n",
    "    plt.grid(b=None)\n",
    "    plt.title(feature)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='../images/obamas.png', width = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
